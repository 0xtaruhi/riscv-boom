diff --git a/src/main/scala/lsu/dcache.scala b/src/main/scala/lsu/dcache.scala
index 8e12022..63df344 100644
--- a/src/main/scala/lsu/dcache.scala
+++ b/src/main/scala/lsu/dcache.scala
@@ -28,9 +28,6 @@ class BoomDCacheReqInternal(implicit p: Parameters) extends BoomDCacheReq()(p)
   val tag_match = Bool()
   val old_meta  = new L1Metadata
   val way_en    = UInt(nWays.W)
-
-  // Used in the MSHRs
-  val sdq_id    = UInt(log2Ceil(cfg.nSDQ).W)
 }
 
 
@@ -40,8 +37,6 @@ class BoomMSHR(id: Int)(implicit edge: TLEdgeOut, p: Parameters) extends BoomMod
   val io = IO(new Bundle {
     val req_pri_val = Input(Bool())
     val req_pri_rdy = Output(Bool())
-    val req_sec_val = Input(Bool())
-    val req_sec_rdy = Output(Bool())
 
     val brinfo       = Input(new BrResolutionInfo)
     val exception    = Input(Bool())
@@ -74,11 +69,6 @@ class BoomMSHR(id: Int)(implicit edge: TLEdgeOut, p: Parameters) extends BoomMod
     val clearable   = Output(Bool())
     val clr_entry   = Input(Bool())
 
-    // Replays go through the cache pipeline again
-    val replay      = Decoupled(new BoomDCacheReqInternal)
-    // Resp go straight out to the core
-    val resp        = Decoupled(new BoomDCacheResp)
-
     val probe_rdy   = Output(Bool())
   })
 
@@ -92,7 +82,7 @@ class BoomMSHR(id: Int)(implicit edge: TLEdgeOut, p: Parameters) extends BoomMod
   // s_meta_write_req  : Write the metadata for new cache lne
   // s_meta_write_resp :
 
-  val s_invalid :: s_refill_req :: s_refill_resp :: s_drain_rpq_loads :: s_wb_req :: s_wb_resp :: s_meta_clear :: s_commit_line :: s_meta_write_req :: s_meta_write_resp :: s_drain_rpq :: Nil = Enum(11)
+  val s_invalid :: s_refill_req :: s_refill_resp :: s_meta_write :: s_wb_req :: s_wb_resp ::  s_commit_line :: Nil = Enum(7)
   val state = RegInit(s_invalid)
 
   val req     = Reg(new BoomDCacheReqInternal)
@@ -109,29 +99,10 @@ class BoomMSHR(id: Int)(implicit edge: TLEdgeOut, p: Parameters) extends BoomMod
   val grow_param = new_coh.onAccess(req.uop.mem_cmd)._2
   val coh_on_grant = new_coh.onGrant(req.uop.mem_cmd, io.mem_grant.bits.param)
 
-  // We only accept secondary misses if we haven't yet sent an Acquire to outer memory
-  // or if the Acquire that was sent will obtain a Grant with sufficient permissions
-  // to let us replay this new request. I.e. we don't handle multiple outstanding
-  // Acquires on the same block for now.
-  val (cmd_requires_second_acquire, is_hit_again, _, dirtier_coh, dirtier_cmd) =
-    new_coh.onSecondaryAccess(req.uop.mem_cmd, io.req.uop.mem_cmd)
-
   val (_, _, refill_done, refill_address_inc) = edge.addr_inc(io.mem_grant)
-  val sec_rdy = (idx_match &&
-                 !cmd_requires_second_acquire &&
-                 !state.isOneOf(s_invalid, s_meta_write_req, s_meta_write_resp, s_drain_rpq))// Always accept secondary misses
-
-  val rpq = Module(new BranchKillableQueue(new BoomDCacheReqInternal, cfg.nRPQ, u => u.uses_ldq))
-  rpq.io.brinfo := io.brinfo
-  rpq.io.flush  := io.exception
-
-  rpq.io.enq.valid := ((io.req_pri_val && io.req_pri_rdy) || (io.req_sec_val && io.req_sec_rdy)) && !isPrefetch(io.req.uop.mem_cmd)
-  rpq.io.enq.bits  := io.req
-  rpq.io.deq.ready := false.B
-
 
   val grantackq = Module(new Queue(new TLBundleE(edge.bundle), 1))
-  val can_finish = state === s_drain_rpq_loads
+  val can_finish = state === s_invalid
   grantackq.io.enq.valid := refill_done && edge.isRequest(io.mem_grant.bits)
   grantackq.io.enq.bits  := edge.GrantAck(io.mem_grant.bits)
   io.mem_finish.valid    := grantackq.io.deq.valid && can_finish
@@ -142,46 +113,40 @@ class BoomMSHR(id: Int)(implicit edge: TLEdgeOut, p: Parameters) extends BoomMod
                         UInt(encRowBits.W))
   val refill_ctr  = Reg(UInt(log2Ceil(cacheDataBeats).W))
   val commit_line = Reg(Bool())
+  val req_has_refill = Reg(Bool())
 
-  io.probe_rdy   := true.B
+  // Block probes if a tag write we started is still in the pipeline
+  val meta_hazard = RegInit(0.U(2.W))
+  when (meta_hazard =/= 0.U) { meta_hazard := meta_hazard + 1.U }
+  when (io.meta_write.fire()) { meta_hazard := 1.U }
+  io.probe_rdy   := (meta_hazard === 0.U)
   io.idx_match   := (state =/= s_invalid) && idx_match
-  io.way_match   := !state.isOneOf(s_invalid, s_refill_req, s_refill_resp, s_drain_rpq_loads) && way_match
+  io.way_match   := !state.isOneOf(s_invalid, s_refill_req, s_refill_resp) && way_match
   io.tag_match   := (state =/= s_invalid) && tag_match
   io.meta_write.valid  := false.B
   io.req_pri_rdy       := false.B
-  io.req_sec_rdy       := sec_rdy && rpq.io.enq.ready
   io.mem_acquire.valid := false.B
   io.refill.valid      := false.B
-  io.replay.valid      := false.B
   io.wb_req.valid      := false.B
-  io.resp.valid        := false.B
   io.commit_val        := false.B
   io.commit_addr       := req.addr
   io.commit_cmd        := Mux(ClientStates.hasWritePermission(new_coh.state), M_PFW, M_PFR)
   io.clearable         := false.B
 
-  when (io.req_sec_val && io.req_sec_rdy) {
-    req.uop.mem_cmd := dirtier_cmd
-    when (is_hit_again) {
-      new_coh := dirtier_coh
-    }
-  }
-
   when (state === s_invalid) {
     io.req_pri_rdy := true.B
 
     when (io.req_pri_val && io.req_pri_rdy) {
-      assert(rpq.io.enq.ready)
       req := io.req
       val old_coh   = io.req.old_meta.coh
       req_needs_wb := old_coh.onCacheControl(M_FLUSH)._1 // does the line we are evicting need to be written back
       val (is_hit, _, coh_on_hit) = old_coh.onAccess(io.req.uop.mem_cmd)
-
+      req_has_refill := false.B
       when (io.req.tag_match) {
         when (is_hit) { // set dirty bit
           assert(isWrite(io.req.uop.mem_cmd))
           new_coh := coh_on_hit
-          state   := s_meta_write_req
+          state   := s_meta_write
         } .otherwise { // upgrade permissions
           new_coh := old_coh
           state   := s_refill_req
@@ -192,6 +157,7 @@ class BoomMSHR(id: Int)(implicit edge: TLEdgeOut, p: Parameters) extends BoomMod
       }
     }
   } .elsewhen (state === s_refill_req) {
+    req_has_refill       := true.B
     io.mem_acquire.valid := true.B
     io.mem_acquire.bits  := edge.AcquireBlock(
       fromSource      = id.U,
@@ -206,43 +172,22 @@ class BoomMSHR(id: Int)(implicit edge: TLEdgeOut, p: Parameters) extends BoomMod
       load_buffer(refill_address_inc >> rowOffBits) := io.mem_grant.bits.data
     }
     when (refill_done) {
-      state := s_drain_rpq_loads
+      // TODO: Don't go straight into meta_write, go into a delay stage and allow reads out of the line buffer
+      state := s_meta_write
       commit_line := false.B
       new_coh := coh_on_grant
     }
-  } .elsewhen (state === s_drain_rpq_loads) {
-    // TODO: This should not be a PNR check
-    // val drain_load = (isRead(rpq.io.deq.bits.uop.mem_cmd) &&
-    //                   (rpq.io.deq.bits.is_hella ||
-    //                     IsOlder(rpq.io.deq.bits.uop.rob_idx, io.rob_pnr_idx, io.rob_head_idx)))
-    val drain_load = isRead(rpq.io.deq.bits.uop.mem_cmd) && !isWrite(rpq.io.deq.bits.uop.mem_cmd)
-    // drain all loads for now
-    val rp_addr = Cat(req_tag, req_idx, rpq.io.deq.bits.addr(blockOffBits-1,0))
-    val word_idx  = if (rowWords == 1) 0.U else rp_addr(log2Up(rowWords*coreDataBytes)-1, log2Up(wordBytes))
-    val data      = load_buffer(rpq.io.deq.bits.addr >> rowOffBits)
-    val data_word = data >> Cat(word_idx, 0.U(log2Up(coreDataBits).W))
-    val loadgen = new LoadGen(rpq.io.deq.bits.uop.mem_size, rpq.io.deq.bits.uop.mem_signed,
-      Cat(req_tag, req_idx, rpq.io.deq.bits.addr(blockOffBits-1,0)),
-      data_word, false.B, wordBytes)
-
-    rpq.io.deq.ready  := io.resp.ready && drain_load
-    io.resp.valid     := rpq.io.deq.valid && drain_load
-    io.resp.bits.uop  := rpq.io.deq.bits.uop
-    io.resp.bits.data := loadgen.data
-    io.resp.bits.is_hella := rpq.io.deq.bits.is_hella
-    when (rpq.io.deq.fire()) {
-      commit_line   := true.B
-      io.commit_val := true.B
-    }
-      .elsewhen (rpq.io.empty && !commit_line)
-    {
-      io.clearable := true.B
-      when (io.clr_entry && !rpq.io.enq.fire()) {
-        state := s_invalid
-      }
-    } .elsewhen (rpq.io.empty || (rpq.io.deq.valid && !drain_load)) {
-      io.commit_val := true.B
-      state := Mux(req_needs_wb, s_wb_req, s_meta_clear)
+  } .elsewhen (state === s_meta_write) {
+    io.meta_write.valid         := true.B
+    io.meta_write.bits.idx      := req_idx
+    io.meta_write.bits.data.coh := new_coh
+    io.meta_write.bits.data.tag := req_tag
+    io.meta_write.bits.way_en   := req.way_en
+    when (io.meta_write.fire()) {
+      refill_ctr := 0.U
+      state      := Mux(req_needs_wb  , s_wb_req,
+                    Mux(req_has_refill, s_commit_line,
+                                        s_invalid))
     }
   } .elsewhen (state === s_wb_req) {
     io.wb_req.valid          := true.B
@@ -258,18 +203,7 @@ class BoomMSHR(id: Int)(implicit edge: TLEdgeOut, p: Parameters) extends BoomMod
     }
   } .elsewhen (state === s_wb_resp) {
     when (io.mem_grant.fire()) {
-      state := s_meta_clear
-    }
-  } .elsewhen (state === s_meta_clear) {
-    io.meta_write.valid         := true.B
-    io.meta_write.bits.idx      := req_idx
-    io.meta_write.bits.data.coh := coh_on_clear
-    io.meta_write.bits.data.tag := req_tag
-    io.meta_write.bits.way_en   := req.way_en
-
-    when (io.meta_write.fire()) {
-      state      := s_commit_line
-      refill_ctr := 0.U
+      state      := Mux(req_has_refill, s_commit_line, s_invalid)
     }
   } .elsewhen (state === s_commit_line) {
     io.refill.valid       := true.B
@@ -280,31 +214,11 @@ class BoomMSHR(id: Int)(implicit edge: TLEdgeOut, p: Parameters) extends BoomMod
     when (io.refill.fire()) {
       refill_ctr := refill_ctr + 1.U
       when (refill_ctr === (cacheDataBeats - 1).U) {
-        state := s_meta_write_req
+        state := s_invalid
       }
     }
-  } .elsewhen (state === s_meta_write_req) {
-    io.meta_write.valid         := true.B
-    io.meta_write.bits.idx      := req_idx
-    io.meta_write.bits.data.coh := new_coh
-    io.meta_write.bits.data.tag := req_tag
-    io.meta_write.bits.way_en   := req.way_en
-    when (io.meta_write.fire()) {
-      state := s_meta_write_resp
-    }
-  } .elsewhen (state === s_meta_write_resp) {
-    // This wait state allows us to catch RAW hazards on the tags
-    state := s_drain_rpq
-  }.elsewhen (state === s_drain_rpq) {
-    io.replay <> rpq.io.deq
-    io.replay.bits.way_en    := req.way_en
-    io.replay.bits.addr := Cat(req_tag, req_idx, rpq.io.deq.bits.addr(blockOffBits-1,0))
-    when (rpq.io.empty ) {
-      state := s_invalid
-    }
   }
 
-
 }
 
 class BoomIOMSHR(id: Int)(implicit edge: TLEdgeOut, p: Parameters) extends BoomModule()(p)
@@ -411,7 +325,6 @@ class BoomMSHRFile(implicit edge: TLEdgeOut, p: Parameters) extends BoomModule()
 
     val refill     = Decoupled(new L1DataWriteReq)
     val meta_write = Decoupled(new L1MetaWriteReq)
-    val replay     = Decoupled(new BoomDCacheReqInternal)
     val prefetch   = Decoupled(new BoomDCacheReq)
     val wb_req     = Decoupled(new WritebackReq(edge.bundle))
 
@@ -429,16 +342,6 @@ class BoomMSHRFile(implicit edge: TLEdgeOut, p: Parameters) extends BoomModule()
 
   val cacheable = edge.manager.supportsAcquireBFast(io.req.bits.addr, lgCacheBlockBytes.U)
 
-  val sdq_val      = RegInit(0.U(cfg.nSDQ.W))
-  val sdq_alloc_id = PriorityEncoder(~sdq_val(cfg.nSDQ-1,0))
-  val sdq_rdy      = !sdq_val.andR
-  val sdq_enq      = io.req.fire() && cacheable && isWrite(io.req.bits.uop.mem_cmd)
-  val sdq          = Mem(cfg.nSDQ, UInt(coreDataBits.W))
-
-  when (sdq_enq) {
-    sdq(sdq_alloc_id) := io.req.bits.data
-  }
-
   val idx_matches = Wire(Vec(cfg.nMSHRs, Bool()))
   val tag_matches = Wire(Vec(cfg.nMSHRs, Bool()))
   val tag_match   = Mux1H(idx_matches, tag_matches)
@@ -447,8 +350,7 @@ class BoomMSHRFile(implicit edge: TLEdgeOut, p: Parameters) extends BoomModule()
 
   val meta_write_arb = Module(new Arbiter(new L1MetaWriteReq           , cfg.nMSHRs))
   val wb_req_arb     = Module(new Arbiter(new WritebackReq(edge.bundle), cfg.nMSHRs))
-  val replay_arb     = Module(new Arbiter(new BoomDCacheReqInternal    , cfg.nMSHRs))
-  val resp_arb       = Module(new Arbiter(new BoomDCacheResp           , cfg.nMSHRs + nIOMSHRs))
+  val resp_arb       = Module(new Arbiter(new BoomDCacheResp           , nIOMSHRs))
   val refill_arb     = Module(new Arbiter(new L1DataWriteReq           , cfg.nMSHRs))
 
   val commit_vals    = Wire(Vec(cfg.nMSHRs, Bool()))
@@ -456,7 +358,6 @@ class BoomMSHRFile(implicit edge: TLEdgeOut, p: Parameters) extends BoomModule()
   val commit_cmds    = Wire(Vec(cfg.nMSHRs, UInt(M_SZ.W)))
 
   var way_match = false.B
-  var sec_rdy   = false.B
 
   io.fence_rdy := true.B
   io.probe_rdy := true.B
@@ -465,7 +366,7 @@ class BoomMSHRFile(implicit edge: TLEdgeOut, p: Parameters) extends BoomModule()
   val mshr_alloc_idx = Wire(UInt())
   val mshr_clear_idx = Wire(UInt())
   val pri_rdy = WireInit(false.B)
-  val pri_val = io.req.valid && sdq_rdy && cacheable && !idx_match
+  val pri_val = io.req.valid && cacheable && !idx_match
   val mshrs = (0 until cfg.nMSHRs) map { i =>
     val mshr = Module(new BoomMSHR(i))
 
@@ -480,22 +381,22 @@ class BoomMSHRFile(implicit edge: TLEdgeOut, p: Parameters) extends BoomModule()
       pri_rdy := mshr.io.req_pri_rdy
     }
 
-    mshr.io.req_sec_val  := io.req.valid && sdq_rdy && tag_match && cacheable
     mshr.io.req          := io.req.bits
-    mshr.io.req.sdq_id   := sdq_alloc_id
 
     mshr.io.brinfo       := io.brinfo
     mshr.io.exception    := io.exception
     mshr.io.rob_pnr_idx  := io.rob_pnr_idx
     mshr.io.rob_head_idx := io.rob_head_idx
 
-    mshr.io.clr_entry    := mshr.io.clearable && ((pri_val && !pri_rdy && (i.U === mshr_clear_idx)) ||              // Clear because no MSHRs are ready
-                                                  io.clear_all                                      ||              // Clear because core is asking us to fence
-                                                  (mshr.io.idx_match && !mshr.io.tag_match)         ||              // Clear because can't have multiple MSHR with same idx
-                                                  (mshr.io.idx_match && mshr.io.tag_match && !mshr.io.req_sec_rdy)) // Clear because we are a write, but this was a prefetch read
+    // mshr.io.clr_entry    := mshr.io.clearable && ((pri_val && !pri_rdy && (i.U === mshr_clear_idx)) ||              // Clear because no MSHRs are ready
+    //                                               io.clear_all                                      ||              // Clear because core is asking us to fence
+    //                                               (mshr.io.idx_match && !mshr.io.tag_match)         ||              // Clear because can't have multiple MSHR with same idx
+    //                                               (mshr.io.idx_match && mshr.io.tag_match && !mshr.io.req_sec_rdy)) // Clear because we are a write, but this was a prefetch read
+    // TODO: Fix prefetches
+    mshr.io.clr_entry    := false.B
+
     meta_write_arb.io.in(i) <> mshr.io.meta_write
     wb_req_arb.io.in(i)     <> mshr.io.wb_req
-    replay_arb.io.in(i)     <> mshr.io.replay
     refill_arb.io.in(i)     <> mshr.io.refill
 
     commit_vals(i)  := mshr.io.commit_val
@@ -505,11 +406,8 @@ class BoomMSHRFile(implicit edge: TLEdgeOut, p: Parameters) extends BoomModule()
     mshr.io.mem_grant.valid := io.mem_grant.valid && io.mem_grant.bits.source === i.U
     mshr.io.mem_grant.bits  := io.mem_grant.bits
 
-    sec_rdy   = sec_rdy || mshr.io.req_sec_rdy
     way_match = way_match || mshr.io.way_match
 
-    resp_arb.io.in(i) <> mshr.io.resp
-
     when (!mshr.io.req_pri_rdy) {
       io.fence_rdy := false.B
     }
@@ -551,7 +449,7 @@ class BoomMSHRFile(implicit edge: TLEdgeOut, p: Parameters) extends BoomModule()
     mshr.io.mem_ack.bits  := io.mem_grant.bits
     mshr.io.mem_ack.valid := io.mem_grant.valid && io.mem_grant.bits.source === id.U
 
-    resp_arb.io.in(id) <> mshr.io.resp
+    resp_arb.io.in(i) <> mshr.io.resp
     when (!mshr.io.req.ready) {
       io.fence_rdy := false.B
     }
@@ -564,21 +462,11 @@ class BoomMSHRFile(implicit edge: TLEdgeOut, p: Parameters) extends BoomModule()
   TLArbiter.lowestFromSeq(edge, io.mem_finish,  mshrs.map(_.io.mem_finish))
 
   io.resp           <> resp_arb.io.out
-  io.req.ready      := Mux(!cacheable, mmio_rdy, sdq_rdy && Mux(idx_match, tag_match && sec_rdy, pri_rdy))
+  io.req.ready      := Mux(!cacheable, mmio_rdy, !idx_match && pri_rdy)
   io.secondary_miss := idx_match && way_match && !tag_match
   io.block_hit      := idx_match && tag_match
   io.refill         <> refill_arb.io.out
 
-  val free_sdq = io.replay.fire() && isWrite(io.replay.bits.uop.mem_cmd)
-  io.replay.bits.data := sdq(RegEnable(replay_arb.io.out.bits.sdq_id, free_sdq))
-
-  io.replay <> replay_arb.io.out
-
-  when (io.replay.valid || sdq_enq) {
-    sdq_val := sdq_val & ~(UIntToOH(replay_arb.io.out.bits.sdq_id) & Fill(cfg.nSDQ, free_sdq)) |
-      PriorityEncoderOH(~sdq_val(cfg.nSDQ-1,0)) & Fill(cfg.nSDQ, sdq_enq)
-  }
-
   prefetcher.io.mshr_avail    := RegNext(pri_rdy)
   prefetcher.io.req_val       := RegNext(commit_vals.reduce(_||_))
   prefetcher.io.req_addr      := RegNext(Mux1H(commit_vals, commit_addrs))
@@ -652,8 +540,8 @@ class BoomNonBlockingDCacheModule(outer: BoomNonBlockingDCache) extends LazyModu
   val meta = Module(new L1MetadataArray(onReset _))
   val metaWriteArb = Module(new Arbiter(new L1MetaWriteReq, 2))
   // 0 goes to MSHR refills, 1 goes to prober
-  val metaReadArb = Module(new Arbiter(new L1MetaReadReq, 5))
-  // 0 goes to MSHR replays, 1 goes to prober, 2 goes to wb, 3 goes to pipeline, 4 goes to prefetch
+  val metaReadArb = Module(new Arbiter(new L1MetaReadReq, 4))
+  // 0 goes to prober, 1 goes to wb, 2 goes to pipeline, 3 goes to prefetch
 
   meta.io.write <> metaWriteArb.io.out
   meta.io.read  <> metaReadArb.io.out
@@ -662,8 +550,8 @@ class BoomNonBlockingDCacheModule(outer: BoomNonBlockingDCache) extends LazyModu
   val data = Module(new DataArray)
   val dataWriteArb = Module(new Arbiter(new L1DataWriteReq, 2))
   // 0 goes to pipeline, 1 goes to MSHR refills
-  val dataReadArb = Module(new Arbiter(new L1DataReadReq, 3))
-  // 0 goes to MSHR replays, 1 goes to wb, 2 goes to pipeline
+  val dataReadArb = Module(new Arbiter(new L1DataReadReq, 2))
+  // 0 goes to wb, 1 goes to pipeline
 
   data.io.write <> dataWriteArb.io.out
   data.io.read  <> dataReadArb.io.out
@@ -671,35 +559,17 @@ class BoomNonBlockingDCacheModule(outer: BoomNonBlockingDCache) extends LazyModu
   // ------------
   // New requests
 
-  io.lsu.req.ready := metaReadArb.io.in(3).ready && dataReadArb.io.in(2).ready
+  io.lsu.req.ready := metaReadArb.io.in(2).ready && dataReadArb.io.in(1).ready
   // Tag read for new requests
-  metaReadArb.io.in(3).valid       := io.lsu.req.valid
-  metaReadArb.io.in(3).bits.idx    := io.lsu.req.bits.addr >> blockOffBits
-  metaReadArb.io.in(3).bits.way_en := DontCare
-  metaReadArb.io.in(3).bits.tag    := DontCare
+  metaReadArb.io.in(2).valid       := io.lsu.req.valid
+  metaReadArb.io.in(2).bits.idx    := io.lsu.req.bits.addr >> blockOffBits
+  metaReadArb.io.in(2).bits.way_en := DontCare
+  metaReadArb.io.in(2).bits.tag    := DontCare
   // Data read for new requests
-  dataReadArb.io.in(2).valid       := io.lsu.req.valid
-  dataReadArb.io.in(2).bits.addr   := io.lsu.req.bits.addr
-  dataReadArb.io.in(2).bits.way_en := ~0.U(nWays.W)
+  dataReadArb.io.in(1).valid       := io.lsu.req.valid
+  dataReadArb.io.in(1).bits.addr   := io.lsu.req.bits.addr
+  dataReadArb.io.in(1).bits.way_en := ~0.U(nWays.W)
 
-  // ------------
-  // MSHR Replays
-  val replay_req = Wire(new BoomDCacheReq)
-  replay_req.uop        := mshrs.io.replay.bits.uop
-  replay_req.addr       := mshrs.io.replay.bits.addr
-  replay_req.data       := mshrs.io.replay.bits.data
-  replay_req.is_hella   := mshrs.io.replay.bits.is_hella
-  mshrs.io.replay.ready := metaReadArb.io.in(0).ready && dataReadArb.io.in(0).ready
-  // Tag read for MSHR replays
-  // We don't actually need to read the metadata, for replays we already know our way
-  metaReadArb.io.in(0).valid       := mshrs.io.replay.valid
-  metaReadArb.io.in(0).bits.idx    := mshrs.io.replay.bits.addr >> blockOffBits
-  metaReadArb.io.in(0).bits.way_en := DontCare
-  metaReadArb.io.in(0).bits.tag    := DontCare
-  // Data read for MSHR replays
-  dataReadArb.io.in(0).valid       := mshrs.io.replay.valid
-  dataReadArb.io.in(0).bits.addr   := mshrs.io.replay.bits.addr
-  dataReadArb.io.in(0).bits.way_en := mshrs.io.replay.bits.way_en
 
   // -----------
   // Write-backs
@@ -711,13 +581,13 @@ class BoomNonBlockingDCacheModule(outer: BoomNonBlockingDCache) extends LazyModu
   wb_req.is_hella := false.B
   // Couple the two decoupled interfaces of the WBUnit's meta_read and data_read
   // Tag read for write-back
-  metaReadArb.io.in(2).valid := wb.io.meta_read.valid
-  metaReadArb.io.in(2).bits  := wb.io.meta_read.bits
-  wb.io.meta_read.ready := metaReadArb.io.in(2).ready && dataReadArb.io.in(1).ready
+  metaReadArb.io.in(1).valid := wb.io.meta_read.valid
+  metaReadArb.io.in(1).bits  := wb.io.meta_read.bits
+  wb.io.meta_read.ready := metaReadArb.io.in(1).ready && dataReadArb.io.in(1).ready
   // Data read for write-back
-  dataReadArb.io.in(1).valid := wb.io.data_req.valid
-  dataReadArb.io.in(1).bits  := wb.io.data_req.bits
-  wb.io.data_req.ready  := metaReadArb.io.in(2).ready && dataReadArb.io.in(1).ready
+  dataReadArb.io.in(0).valid := wb.io.data_req.valid
+  dataReadArb.io.in(0).bits  := wb.io.data_req.bits
+  wb.io.data_req.ready  := metaReadArb.io.in(1).ready && dataReadArb.io.in(0).ready
   assert(!(wb.io.meta_read.fire() ^ wb.io.data_req.fire()))
 
   // -------
@@ -729,7 +599,7 @@ class BoomNonBlockingDCacheModule(outer: BoomNonBlockingDCache) extends LazyModu
   prober_req.data     := DontCare
   prober_req.is_hella := false.B
   // Tag read for prober
-  metaReadArb.io.in(1)  <> prober.io.meta_read
+  metaReadArb.io.in(0)  <> prober.io.meta_read
   // Prober does not need to read data array
 
   // -------
@@ -737,20 +607,20 @@ class BoomNonBlockingDCacheModule(outer: BoomNonBlockingDCache) extends LazyModu
   val prefetch_fire = mshrs.io.prefetch.fire()
   val prefetch_req  = mshrs.io.prefetch.bits
   // Tag read for prefetch
-  metaReadArb.io.in(4).valid       := mshrs.io.prefetch.valid
-  metaReadArb.io.in(4).bits.idx    := mshrs.io.prefetch.bits.addr >> blockOffBits
-  metaReadArb.io.in(4).bits.way_en := DontCare
-  metaReadArb.io.in(4).bits.tag    := DontCare
-  mshrs.io.prefetch.ready := metaReadArb.io.in(4).ready
+  metaReadArb.io.in(3).valid       := mshrs.io.prefetch.valid
+  metaReadArb.io.in(3).bits.idx    := mshrs.io.prefetch.bits.addr >> blockOffBits
+  metaReadArb.io.in(3).bits.way_en := DontCare
+  metaReadArb.io.in(3).bits.tag    := DontCare
+  mshrs.io.prefetch.ready := metaReadArb.io.in(3).ready
   // Prefetch does not need to read data array
 
-  val s0_valid = io.lsu.req.fire() || mshrs.io.replay.fire() || wb_fire || prober_fire || prefetch_fire
+  val s0_valid = io.lsu.req.fire() || wb_fire || prober_fire || prefetch_fire
   val s0_req   = Mux(io.lsu.req.fire(), io.lsu.req.bits,
                  Mux(wb_fire          , wb_req,
                  Mux(prober_fire      , prober_req,
                  Mux(prefetch_fire    , prefetch_req
-                                      , replay_req))))
-  val s0_send_resp_or_nack = io.lsu.req.fire() || (mshrs.io.replay.fire() && isRead(mshrs.io.replay.bits.uop.mem_cmd)) // Does this request need to send a response or nack
+                                      , (0.U).asTypeOf(new BoomDCacheReq)))))
+  val s0_send_resp_or_nack = io.lsu.req.fire()
 
   val s1_req          = RegNext(s0_req)
   s1_req.uop.br_mask := GetNewBrMask(io.lsu.brinfo, s0_req.uop)
@@ -767,13 +637,14 @@ class BoomNonBlockingDCacheModule(outer: BoomNonBlockingDCache) extends LazyModu
   val s1_send_resp_or_nack = RegNext(s0_send_resp_or_nack)
   val s1_is_lsu        = RegNext(io.lsu.req.fire()) // TODO make this a bundle
   val s1_is_probe      = RegNext(prober_fire)
-  val s1_is_replay     = RegNext(mshrs.io.replay.fire())
-  val s1_replay_way_en = RegNext(mshrs.io.replay.bits.way_en) // For replays, the metadata isn't written yet
+  val s1_is_wb         = RegNext(wb.io.meta_read.fire())
+  val s1_wb_way_en     = RegNext(wb.io.data_req.bits.way_en)
 
   // tag check
   def wayMap[T <: Data](f: Int => T) = VecInit((0 until nWays).map(f))
   val s1_tag_eq_way = wayMap((w: Int) => meta.io.resp(w).tag === (s1_addr >> untagBits)).asUInt
-  val s1_tag_match_way = Mux(s1_is_replay, s1_replay_way_en, wayMap((w: Int) => s1_tag_eq_way(w) && meta.io.resp(w).coh.isValid()).asUInt)
+  val s1_tag_match_way = Mux(s1_is_wb,     s1_wb_way_en,
+      wayMap((w: Int) => s1_tag_eq_way(w) && meta.io.resp(w).coh.isValid()).asUInt)
 
 
   val s2_req   = RegNext(s1_req)
@@ -785,7 +656,6 @@ class BoomNonBlockingDCacheModule(outer: BoomNonBlockingDCache) extends LazyModu
   s2_req.uop.br_mask := GetNewBrMask(io.lsu.brinfo, s1_req.uop)
   val s2_is_lsu    = RegNext(s1_is_lsu)
   val s2_is_probe  = RegNext(s1_is_probe)
-  val s2_is_replay = RegNext(s1_is_replay)
 
 
   val s2_tag_match_way = RegNext(s1_tag_match_way)
@@ -793,8 +663,7 @@ class BoomNonBlockingDCacheModule(outer: BoomNonBlockingDCache) extends LazyModu
   val s2_hit_state = Mux1H(s2_tag_match_way, wayMap((w: Int) => RegNext(meta.io.resp(w).coh)))
   val (s2_has_permission, _, s2_new_hit_state) = s2_hit_state.onAccess(s2_req.uop.mem_cmd)
   //
-  val s2_hit = (s2_tag_match && (s2_has_permission && s2_hit_state === s2_new_hit_state) && !mshrs.io.block_hit) || s2_is_replay
-  assert(!(s2_is_replay && !s2_hit), "Replays should always hit")
+  val s2_hit = (s2_tag_match && (s2_has_permission && s2_hit_state === s2_new_hit_state) && !mshrs.io.block_hit)
 
   // lr/sc
   val lrsc_count = RegInit(0.U(log2Ceil(lrscCycles).W))
@@ -805,7 +674,7 @@ class BoomNonBlockingDCacheModule(outer: BoomNonBlockingDCache) extends LazyModu
   val s2_lrsc_addr_match = lrsc_valid && lrsc_addr === (s2_req.addr >> blockOffBits)
   val s2_sc_fail = s2_sc && !s2_lrsc_addr_match
   when (lrsc_count > 0.U) { lrsc_count := lrsc_count - 1.U }
-  when ((s2_valid && s2_hit) || (s2_is_replay && s2_req.uop.mem_cmd =/= M_FLUSH_ALL)) {
+  when ((s2_valid && s2_hit)) {
     when (s2_lr) {
       lrsc_count := (lrscCycles - 1).U
       lrsc_addr := s2_req.addr >> blockOffBits
@@ -835,7 +704,8 @@ class BoomNonBlockingDCacheModule(outer: BoomNonBlockingDCache) extends LazyModu
   val s2_nack_hit    = RegNext(s1_nack) // nack because of incoming probe
   val s2_nack_victim = s2_valid &&  s2_hit && mshrs.io.secondary_miss // Nack when we hit something currently being evicted
   val s2_nack_miss   = s2_valid && !s2_hit && !mshrs.io.req.ready // MSHRs not ready for request
-  val s2_nack        = (s2_nack_miss || s2_nack_hit || s2_nack_victim) && !s2_is_replay
+  val s2_nack_mshr   = s2_valid && mshrs.io.req.fire()
+  val s2_nack        =  s2_nack_miss || s2_nack_hit || s2_nack_victim || s2_nack_mshr
   val s2_send_resp = (RegNext(s1_send_resp_or_nack) && !s2_nack &&
                       (s2_hit || (mshrs.io.req.fire() && isWrite(s2_req.uop.mem_cmd) && !isRead(s2_req.uop.mem_cmd))))
   val s2_send_nack = (RegNext(s1_send_resp_or_nack) && s2_nack)
@@ -856,14 +726,12 @@ class BoomNonBlockingDCacheModule(outer: BoomNonBlockingDCache) extends LazyModu
                         (isPrefetch(s2_req.uop.mem_cmd) ||
                          isRead(s2_req.uop.mem_cmd) ||
                          isWrite(s2_req.uop.mem_cmd))
-  assert(!(mshrs.io.req.valid && s2_is_replay), "Replays should not need to go back into MSHRs")
   mshrs.io.req.bits.uop         := s2_req.uop
   mshrs.io.req.bits.uop.br_mask := GetNewBrMask(io.lsu.brinfo, s2_req.uop)
   mshrs.io.req.bits.addr        := s2_req.addr
   mshrs.io.req.bits.tag_match   := s2_tag_match
   mshrs.io.req.bits.old_meta    := Mux(s2_tag_match, L1Metadata(s2_repl_meta.tag, s2_hit_state), s2_repl_meta)
   mshrs.io.req.bits.way_en      := Mux(s2_tag_match, s2_tag_match_way, s2_replaced_way_en)
-  mshrs.io.req.bits.sdq_id      := DontCare // this is set inside MSHR
   mshrs.io.req.bits.data        := s2_req.data
   mshrs.io.req.bits.is_hella    := s2_req.is_hella
   when (mshrs.io.req.fire()) { replacer.miss }
